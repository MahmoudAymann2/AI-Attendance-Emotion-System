<h1>ğŸ§  Real Time Attendance & Emotion Detection System â€“ Technical Details</h1>

<h2>ğŸ—‚ï¸ 1. Project Overview</h2>
<p>This project is a Flask-based web application that provides:</p>
<ul>
  <li>ğŸ“ Face Recognition-based Attendance Tracking</li>
  <li>ğŸ˜Š Facial Emotion Detection using a CNN model</li>
  <li>ğŸ§¾ CSV & DB storage</li>
  <li>ğŸ“§ Email notifications</li>
  <li>ğŸ–¥ï¸ Live webcam feed UI</li>
</ul>
<p>Itâ€™s designed for educational institutions, workplaces, or events to automate the process of monitoring attendance and capturing emotional context in real time.</p>

<h2>ğŸ§¬ 2. How Face Embeddings Are Saved in the Database</h2>
<h3>ğŸ“Œ What is a Face Embedding?</h3>
<p>A face embedding is a vector (typically 128-dimensional) that represents the unique features of a personâ€™s face. Itâ€™s a compressed numerical fingerprint generated by a pre-trained deep neural network (DNN).</p>

<h3>ğŸ“· Steps to Capture and Store:</h3>
<ol>
  <li>Capture a frame from the webcam (via OpenCV).</li>
  <li>Convert the frame to RGB and extract facial features using <code>face_recognition.face_encodings()</code>:</li>
</ol>

<pre><code>encodings = face_recognition.face_encodings(rgb_frame)</code></pre>

<p>Pickle (serialize) the encoding and save it to SQLite:</p>
<pre><code>pickle.dumps(encodings[0])</code></pre>

<p>Store in the users table:</p>
<pre><code>CREATE TABLE IF NOT EXISTS users (
  name TEXT PRIMARY KEY,
  age INTEGER,
  email TEXT,
  face_encoding BLOB
);</code></pre>

<p>Each user has one embedding (128 values) stored as a binary blob.</p>

<h2>ğŸ” 3. How Face Recognition Works</h2>

<h3>ğŸ”— Matching Algorithm:</h3>
<ul>
  <li><strong>Frame Input:</strong> Captured from webcam using OpenCV.</li>
  <li><strong>Face Detection:</strong> Via <code>face_recognition.face_locations()</code> (uses dlibâ€™s HOG or CNN).</li>
  <li><strong>Embedding Computation:</strong> A new 128D vector is generated from the frame.</li>
  <li><strong>Compare Encodings:</strong> For each known user:</li>
</ul>

<pre><code>face_recognition.face_distance([known_encoding], current_encoding)</code></pre>

<p>This computes the Euclidean distance between known and detected encodings.</p>
<p><strong>Threshold Check:</strong><br>If distance <code>&lt; 0.4</code> â†’ itâ€™s considered a match (tunable).</p>

<h3>ğŸ§  Example:</h3>

<pre><code>[0.01, 0.15, -0.04, ..., 0.23]  # 128 floats
[0.02, 0.14, -0.03, ..., 0.24]</code></pre>

<p>System compares using:</p>
<pre><code>distance = np.linalg.norm(enc1 - enc2)</code></pre>
<p>If <code>distance &lt; 0.4</code>, the user is marked "Present".</p>

<h2>ğŸ˜Š 4. Emotion Detection â€“ Model Details</h2>

<h3>ğŸ“¦ Model Used:</h3>
<ul>
  <li>CNN trained on grayscale 48x48 images.</li>
  <li>Model file: <code>face_model.h5</code></li>
  <li>Dataset: FER2013 or similar (Softmax output layer)</li>
</ul>

<h3>ğŸ“ Emotion Classes:</h3>
<pre><code>['Angry', 'Disgusted', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']</code></pre>

<h3>ğŸ” Pipeline:</h3>
<ol>
  <li>Capture image via canvas from webcam.</li>
  <li>Convert to grayscale.</li>
  <li>Detect face via <code>cv2.CascadeClassifier</code>.</li>
  <li>Crop and resize to 48x48.</li>
  <li>Normalize and reshape:</li>
</ol>

<pre><code>face = face.astype("float") / 255.0
face = img_to_array(face)
face = np.expand_dims(face, axis=0)</code></pre>

<p>Pass to model:</p>
<pre><code>prediction = model.predict(face)
emotion = class_names[np.argmax(prediction)]</code></pre>

<p>Updates every 2 seconds via JavaScript.</p>

<h2>ğŸ—ï¸ 5. System Architecture</h2>

<h3>ğŸ§± Components:</h3>
<ul>
  <li><strong>Frontend:</strong>
    <ul>
      <li>HTML/CSS/JavaScript (vanilla)</li>
      <li>Live webcam via <code>&lt;video&gt;</code> + <code>&lt;canvas&gt;</code></li>
      <li>AJAX to Flask endpoints</li>
    </ul>
  </li>
  <li><strong>Backend (Flask):</strong>
    <ul>
      <li>Video Streaming (OpenCV)</li>
      <li>Face recognition (<code>face_recognition</code>)</li>
      <li>Emotion prediction (Keras)</li>
    </ul>
  </li>
  <li><strong>Database:</strong> SQLite</li>
  <li><strong>Email:</strong> smtplib</li>
</ul>

<h3>ğŸ“Š Data Flow:</h3>
<pre><code>
User Registers (name, age, email)
    â†“
Face Encoding â†’ Pickled â†’ Stored in SQLite
    â†“
Live Attendance Feed â†’ Webcam Stream
    â†“
Faces detected â†’ Embeddings computed
    â†“
Compared to DB embeddings â†’ Attendance marked
    â†“
On Stop:
  â†’ Attendance saved to CSV
  â†’ Sent via email (if configured)
</code></pre>

<h2>ğŸ§ª 6. Attendance Matrix Logic</h2>
<p>When attendance is saved:</p>
<ul>
  <li>All known users (in DB) are looped through.</li>
  <li>For each:</li>
</ul>

<pre><code>status = "Present" if name in present_users else "Absent"</code></pre>

<p>Stored with timestamp in:</p>
<ul>
  <li>.csv file</li>
  <li>SQLite attendance table</li>
</ul>

<h3>CSV structure:</h3>
<pre><code>Name, Age, Email, Timestamp
Mahmoud, 21, mahmoud@example.com, 2025-07-22 10:30:00</code></pre>

<h2>âš™ï¸ 7. Technologies Used</h2>

<table>
  <thead>
    <tr><th>Category</th><th>Tools / Libraries</th></tr>
  </thead>
  <tbody>
    <tr><td>Web Framework</td><td>Flask</td></tr>
    <tr><td>Frontend</td><td>HTML, CSS, JS (Canvas, Webcam API)</td></tr>
    <tr><td>Computer Vision</td><td>OpenCV, face_recognition (dlib)</td></tr>
    <tr><td>Machine Learning</td><td>TensorFlow, Keras (CNN)</td></tr>
    <tr><td>Database</td><td>SQLite + Pickle</td></tr>
    <tr><td>Email</td><td>smtplib, EmailMessage</td></tr>
  </tbody>
</table>
