<h1>🧠 Real Time Attendance & Emotion Detection System – Technical Details</h1>

<h2>🗂️ 1. Project Overview</h2>
<p>This project is a Flask-based web application that provides:</p>
<ul>
  <li>🎓 Face Recognition-based Attendance Tracking</li>
  <li>😊 Facial Emotion Detection using a CNN model</li>
  <li>🧾 CSV & DB storage</li>
  <li>📧 Email notifications</li>
  <li>🖥️ Live webcam feed UI</li>
</ul>
<p>It’s designed for educational institutions, workplaces, or events to automate the process of monitoring attendance and capturing emotional context in real time.</p>

<h2>🧬 2. How Face Embeddings Are Saved in the Database</h2>
<h3>📌 What is a Face Embedding?</h3>
<p>A face embedding is a vector (typically 128-dimensional) that represents the unique features of a person’s face. It’s a compressed numerical fingerprint generated by a pre-trained deep neural network (DNN).</p>

<h3>📷 Steps to Capture and Store:</h3>
<ol>
  <li>Capture a frame from the webcam (via OpenCV).</li>
  <li>Convert the frame to RGB and extract facial features using <code>face_recognition.face_encodings()</code>:</li>
</ol>

<pre><code>encodings = face_recognition.face_encodings(rgb_frame)</code></pre>

<p>Pickle (serialize) the encoding and save it to SQLite:</p>
<pre><code>pickle.dumps(encodings[0])</code></pre>

<p>Store in the users table:</p>
<pre><code>CREATE TABLE IF NOT EXISTS users (
  name TEXT PRIMARY KEY,
  age INTEGER,
  email TEXT,
  face_encoding BLOB
);</code></pre>

<p>Each user has one embedding (128 values) stored as a binary blob.</p>

<h2>🔍 3. How Face Recognition Works</h2>

<h3>🔗 Matching Algorithm:</h3>
<ul>
  <li><strong>Frame Input:</strong> Captured from webcam using OpenCV.</li>
  <li><strong>Face Detection:</strong> Via <code>face_recognition.face_locations()</code> (uses dlib’s HOG or CNN).</li>
  <li><strong>Embedding Computation:</strong> A new 128D vector is generated from the frame.</li>
  <li><strong>Compare Encodings:</strong> For each known user:</li>
</ul>

<pre><code>face_recognition.face_distance([known_encoding], current_encoding)</code></pre>

<p>This computes the Euclidean distance between known and detected encodings.</p>
<p><strong>Threshold Check:</strong><br>If distance <code>&lt; 0.4</code> → it’s considered a match (tunable).</p>

<h3>🧠 Example:</h3>

<pre><code>[0.01, 0.15, -0.04, ..., 0.23]  # 128 floats
[0.02, 0.14, -0.03, ..., 0.24]</code></pre>

<p>System compares using:</p>
<pre><code>distance = np.linalg.norm(enc1 - enc2)</code></pre>
<p>If <code>distance &lt; 0.4</code>, the user is marked "Present".</p>

<h2>😊 4. Emotion Detection – Model Details</h2>

<h3>📦 Model Used:</h3>
<ul>
  <li>CNN trained on grayscale 48x48 images.</li>
  <li>Model file: <code>face_model.h5</code></li>
  <li>Dataset: FER2013 or similar (Softmax output layer)</li>
</ul>

<h3>📁 Emotion Classes:</h3>
<pre><code>['Angry', 'Disgusted', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']</code></pre>

<h3>🔍 Pipeline:</h3>
<ol>
  <li>Capture image via canvas from webcam.</li>
  <li>Convert to grayscale.</li>
  <li>Detect face via <code>cv2.CascadeClassifier</code>.</li>
  <li>Crop and resize to 48x48.</li>
  <li>Normalize and reshape:</li>
</ol>

<pre><code>face = face.astype("float") / 255.0
face = img_to_array(face)
face = np.expand_dims(face, axis=0)</code></pre>

<p>Pass to model:</p>
<pre><code>prediction = model.predict(face)
emotion = class_names[np.argmax(prediction)]</code></pre>

<p>Updates every 2 seconds via JavaScript.</p>

<h2>🏗️ 5. System Architecture</h2>

<h3>🧱 Components:</h3>
<ul>
  <li><strong>Frontend:</strong>
    <ul>
      <li>HTML/CSS/JavaScript (vanilla)</li>
      <li>Live webcam via <code>&lt;video&gt;</code> + <code>&lt;canvas&gt;</code></li>
      <li>AJAX to Flask endpoints</li>
    </ul>
  </li>
  <li><strong>Backend (Flask):</strong>
    <ul>
      <li>Video Streaming (OpenCV)</li>
      <li>Face recognition (<code>face_recognition</code>)</li>
      <li>Emotion prediction (Keras)</li>
    </ul>
  </li>
  <li><strong>Database:</strong> SQLite</li>
  <li><strong>Email:</strong> smtplib</li>
</ul>

<h3>📊 Data Flow:</h3>
<pre><code>
User Registers (name, age, email)
    ↓
Face Encoding → Pickled → Stored in SQLite
    ↓
Live Attendance Feed → Webcam Stream
    ↓
Faces detected → Embeddings computed
    ↓
Compared to DB embeddings → Attendance marked
    ↓
On Stop:
  → Attendance saved to CSV
  → Sent via email (if configured)
</code></pre>

<h2>🧪 6. Attendance Matrix Logic</h2>
<p>When attendance is saved:</p>
<ul>
  <li>All known users (in DB) are looped through.</li>
  <li>For each:</li>
</ul>

<pre><code>status = "Present" if name in present_users else "Absent"</code></pre>

<p>Stored with timestamp in:</p>
<ul>
  <li>.csv file</li>
  <li>SQLite attendance table</li>
</ul>

<h3>CSV structure:</h3>
<pre><code>Name, Age, Email, Timestamp
Mahmoud, 21, mahmoud@example.com, 2025-07-22 10:30:00</code></pre>

<h2>⚙️ 7. Technologies Used</h2>

<table>
  <thead>
    <tr><th>Category</th><th>Tools / Libraries</th></tr>
  </thead>
  <tbody>
    <tr><td>Web Framework</td><td>Flask</td></tr>
    <tr><td>Frontend</td><td>HTML, CSS, JS (Canvas, Webcam API)</td></tr>
    <tr><td>Computer Vision</td><td>OpenCV, face_recognition (dlib)</td></tr>
    <tr><td>Machine Learning</td><td>TensorFlow, Keras (CNN)</td></tr>
    <tr><td>Database</td><td>SQLite + Pickle</td></tr>
    <tr><td>Email</td><td>smtplib, EmailMessage</td></tr>
  </tbody>
</table>
